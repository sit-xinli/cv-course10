{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759876c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(hasattr(cv2, 'ximgproc'))  # True ならOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4764b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = cv2.imread('data/IMG_8297.jpg')\n",
    "img2 = cv2.imread('data/IMG_8298.jpg')\n",
    "img1 = cv2.resize(img1, ((int)(img1.shape[1]/4), (int)(img1.shape[0]/4)))\n",
    "h,w, c = img1.shape\n",
    "\n",
    "# resize img2 to match img1 \n",
    "img2= cv2.resize(img2, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "img12 = np.hstack((img1, img2))\n",
    "\n",
    "cv2.namedWindow('OriginalImage', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('OriginalImage', img12)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea4878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "img1_kp = cv2.drawKeypoints(img1, kp1, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "img2_kp = cv2.drawKeypoints(img2, kp2, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "img12_kp = np.hstack((img1_kp, img2_kp))\n",
    "cv2.namedWindow('FeaturePoints', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('FeaturePoints', img12_kp)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f8cda92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf = cv2.BFMatcher()\n",
    "matches = bf.match(des1, des2)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches[:200], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.namedWindow('MatchedPoints', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('MatchedPoints', img_matches)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c49eb",
   "metadata": {},
   "source": [
    "### 最近隣距離比により、良いマッチングペアを選出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c87535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_rt = bf.knnMatch(des1, des2, k=2)\n",
    "good_matches = []\n",
    "for m,n in matches_rt:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "good_matches = sorted(good_matches, key = lambda x:x.distance)\n",
    "img_good_matches = cv2.drawMatches(img1, kp1, img2, kp2, good_matches[:200], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.namedWindow('MatchedPoints200', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('MatchedPoints200', img_good_matches)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b490426",
   "metadata": {},
   "source": [
    "### 最近距離比から選出した良いマッチングペアにより基礎行列Fを計算する。算出したFにより外れポイントを外す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f4e4490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts1 = []\n",
    "pts2 = []\n",
    "\n",
    "for i,m in enumerate(good_matches):\n",
    "    pts1.append(kp1[m.queryIdx].pt)\n",
    "    pts2.append(kp2[m.trainIdx].pt)\n",
    "\n",
    "import numpy as np\n",
    "pts1 = np.int32(pts1)\n",
    "pts2 = np.int32(pts2)\n",
    "F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.RANSAC)\n",
    "\n",
    "pts1_inliers = pts1[mask.ravel() == 1]\n",
    "pts2_inliers = pts2[mask.ravel() == 1]\n",
    "\n",
    "good_matches_inliers = [m for i,m in enumerate(good_matches[:200]) if mask[i,0] == 1]\n",
    "\n",
    "img_good_matches_inliers = cv2.drawMatches(img1,kp1,img2,kp2,good_matches_inliers[:200],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.namedWindow('GoodMatchedPoints', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('GoodMatchedPoints', img_good_matches_inliers)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9d203d",
   "metadata": {},
   "source": [
    "### エピポーラ線を描画する。\n",
    "- エピポーラ線 ax+by+c=0の(a,b,c)は(r[0],r[1],[r[2]])\n",
    "- エピポーラ線の両端はx=0の時とx=画像幅の時"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1930af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drawlines(img1,img2,lines,pts1,pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    r,c,ch = img1.shape\n",
    "    for r,pt1,pt2 in zip(lines,pts1,pts2):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        img1 = cv2.line(img1, (x0,y0), (x1,y1), color,1)\n",
    "        img1 = cv2.circle(img1,tuple(pt1),5,color,-1)\n",
    "        img2 = cv2.circle(img2,tuple(pt2),5,color,-1)\n",
    "    return img1,img2\n",
    "\n",
    "pts1_inliers_200 = pts1_inliers[0:200,:]\n",
    "pts2_inliers_200 = pts2_inliers[0:200,:]\n",
    "\n",
    "lines1 = cv2.computeCorrespondEpilines(pts2_inliers_200.reshape(-1,1,2),2,F)\n",
    "lines1 = lines1.reshape(-1,3)\n",
    "img5,img6 = drawlines(img1.copy(),img2.copy(),lines1,pts1,pts2)\n",
    "lines2 = cv2.computeCorrespondEpilines(pts1_inliers_200.reshape(-1,1,2),1,F)\n",
    "lines2 = lines2.reshape(-1,3)\n",
    "img3,img4 = drawlines(img2.copy(),img1.copy(),lines2,pts2,pts1)\n",
    "img35 = np.hstack((img3,img5))\n",
    "cv2.namedWindow('EpipoleLines', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('EpipoleLines', img35)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baab0ff",
   "metadata": {},
   "source": [
    "### さらに、Fで外れ値を削除した後の200個のペアを選んでにより基礎行列Fを計算して、エピポーラ線を可視化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "878b2ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F, mask = cv2.findFundamentalMat(pts1[0:200,:], pts2[0:200,:], cv2.FM_RANSAC)\n",
    "\n",
    "pts1 = pts1[0:200,:]\n",
    "pts2 = pts2[0:200,:]\n",
    "pts1_inliers = pts1[mask.ravel() == 1]\n",
    "pts2_inliers = pts2[mask.ravel() == 1]\n",
    "\n",
    "pts1_inliers_200 = pts1_inliers[0:200,:]\n",
    "pts2_inliers_200 = pts2_inliers[0:200,:]\n",
    "\n",
    "lines1 = cv2.computeCorrespondEpilines(pts2_inliers_200.reshape(-1,1,2),2,F)\n",
    "lines1 = lines1.reshape(-1,3)\n",
    "img5,img6 = drawlines(img1.copy(),img2.copy(),lines1,pts1,pts2)\n",
    "lines2 = cv2.computeCorrespondEpilines(pts1_inliers_200.reshape(-1,1,2),1,F)\n",
    "lines2 = lines2.reshape(-1,3)\n",
    "img3,img4 = drawlines(img2.copy(),img1.copy(),lines2,pts2,pts1)\n",
    "img35 = np.hstack((img3,img5))\n",
    "cv2.namedWindow('GoodEpipoleLines', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('GoodEpipoleLines', img35)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bf300a",
   "metadata": {},
   "source": [
    "## F から整列するホモグラフィ変換Ｈ１，Ｈ２を得て、整列後の画像枠を計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97ac3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w ,c= img1.shape\n",
    "retval, H1, H2 = cv2.stereoRectifyUncalibrated(\n",
    "    np.float32(pts1[mask.ravel() == 1]),\n",
    "    np.float32(pts2[mask.ravel() == 1]),\n",
    "    F, imgSize=(w, h)\n",
    ")\n",
    "\n",
    "imgL_rectify = cv2.warpPerspective(img1, H1, (w, h))\n",
    "imgR_rectify = cv2.warpPerspective(img2, H2, (w, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c678426",
   "metadata": {},
   "source": [
    "## ステレオマッチングでStereoデプス推定\n",
    "https://cvml-expertguide.net/terms/cv/camera-geometry/stereo-matching/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88220111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. SGBMステレオマッチング\n",
    "min_disp = 0\n",
    "num_disp = 16 * 5  # 16の倍数\n",
    "block_size = 6\n",
    "\n",
    "stereo = cv2.StereoSGBM_create(\n",
    "    minDisparity=min_disp,\n",
    "    numDisparities=num_disp,\n",
    "    blockSize=block_size,\n",
    "    P1=8 * 1 * block_size ** 2,\n",
    "    P2=32 * 1 * block_size ** 2,\n",
    "    disp12MaxDiff=1,\n",
    "    uniquenessRatio=10,\n",
    "    speckleWindowSize=100,\n",
    "    speckleRange=32\n",
    ")\n",
    "disparity = stereo.compute(imgL_rectify, imgR_rectify).astype(np.float32) / 16.0\n",
    "disparity = cv2.normalize(disparity, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "cv2.namedWindow('DisparityMap(SGBM)', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"DisparityMap(SGBM)\", disparity)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f890979e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uv add opencv-contrib-python for cv2.filterSpeckles\n",
    "disparity_filtered = np.uint8(disparity)\n",
    "cv2.filterSpeckles(disparity_filtered, newVal=0, maxSpeckleSize=100, maxDiff=16*5)\n",
    "\n",
    "# 正規化して表示用に変換\n",
    "disparity_filtered = cv2.normalize(disparity_filtered, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "cv2.namedWindow('DisparityMap(Filtered)', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"DisparityMap(Filtered)\", np.hstack((disparity,disparity_filtered)))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e3c67",
   "metadata": {},
   "source": [
    "## エネルギー関数最小化デプスマップ改善\n",
    "use [ uv add PyMaxflow ] to add library\n",
    "下記のコードはエラーになる。原因は、pythonのバージョンとmaxflowのバージョンが合わないと推測。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f2a091b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'maxflow' has no attribute 'Graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m h, w = disparity.shape\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# グラフ構築\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m g = \u001b[43mmaxflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGraph\u001b[49m[\u001b[38;5;28mfloat\u001b[39m]()\n\u001b[32m     17\u001b[39m nodes = g.add_grid_nodes((h, w))\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Smoothness: 画素間のスムーズネス（定数罰則）\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'maxflow' has no attribute 'Graph'"
     ]
    }
   ],
   "source": [
    "\n",
    "import maxflow\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 欠損値やノイズを除去\n",
    "disparity[disparity < 0] = 0\n",
    "\n",
    "# データ項：視差マップの中央値との差を使う\n",
    "disp_median = np.median(disparity)\n",
    "data_cost = np.abs(disparity - disp_median)\n",
    "\n",
    "# サイズ\n",
    "h, w = disparity.shape\n",
    "\n",
    "# グラフ構築\n",
    "g = maxflow.Graph[float]()\n",
    "nodes = g.add_grid_nodes((h, w))\n",
    "\n",
    "# Smoothness: 画素間のスムーズネス（定数罰則）\n",
    "structure = np.array([[0, 1, 0],\n",
    "                      [1, 0, 1],\n",
    "                      [0, 1, 0]])\n",
    "\n",
    "smoothness_weight = 5.0\n",
    "g.add_grid_edges(nodes, smoothness_weight, structure=structure, symmetric=True)\n",
    "\n",
    "# Data term: 各画素にターミナルエッジ\n",
    "# ここではラベル0：median近い（前景）、ラベル1：外れ値（背景）とみなす\n",
    "data_term_foreground = data_cost          # 視差が中央値に近いとコスト小 → foreground\n",
    "data_term_background = 1.0 - data_cost    # 離れてると背景（単純化）\n",
    "\n",
    "# 正規化（0〜1）\n",
    "data_term_foreground = (data_term_foreground - data_term_foreground.min()) / (data_term_foreground.max() - data_term_foreground.min())\n",
    "data_term_background = 1.0 - data_term_foreground\n",
    "\n",
    "# ターミナルエッジ追加\n",
    "g.add_grid_tedges(nodes, data_term_foreground, data_term_background)\n",
    "\n",
    "# 最小カット実行\n",
    "flow = g.maxflow()\n",
    "segments = g.get_grid_segments(nodes)\n",
    "\n",
    "# 最終ラベルマップ作成\n",
    "optimized_mask = np.int32(~segments)  # True: foreground, False: background\n",
    "\n",
    "# 改善視差マップ：foreground のみ保持、背景はゼロに\n",
    "refined_disparity = disparity * optimized_mask\n",
    "\n",
    "cv2.namedWindow('graph_cuts', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"graph_cuts\", refined_disparity)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-course10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
